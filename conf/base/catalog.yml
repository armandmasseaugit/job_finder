# Parquet file containing all useful information on all recently scraped jobs
# (company name, offer publication date, job title etc.) - Much faster than Excel!
wttj_jobs_output:
  type: pandas.ParquetDataset
  filepath: "abfs://wttj-scraping/wttj_jobs.parquet"
  credentials: azure_credentials

# Scraping timestamp JSON file to track the last scraping date for wttj
wttj_last_scrape:
  type: job_finder.datasets.OptionalJSONDataset
  filepath: "abfs://wttj-scraping/wttj_last_scrape.json"
  credentials: azure_credentials
  default_data: {}

# JSON file containing all the references of the jobs from wttj_jobs.xlsx file
# that were liked or disliked. Its structure is {"ref of the offer 1": "like",
# "ref of the offer 2": "dislike" ...}.
job_likes:
  type: job_finder.datasets.OptionalJSONDataset
  filepath: "abfs://liked-jobs/job_likes.json"
  credentials: azure_credentials
  default_data: {}

# Previous model
rl_model_old:
  type: pickle.PickleDataset #job_finder.datasets.OptionalPickleDataset
  filepath: "abfs://wttj-scraping/rl_model.pkl"
  versioned: true
  credentials: azure_credentials

# New model that has been retrained with job_likes and wttj_jobs data
rl_model_new:
  type: pickle.PickleDataset #job_finder.datasets.OptionalPickleDataset
  filepath: "abfs://wttj-scraping/rl_model.pkl"
  versioned: true
  credentials: azure_credentials

# JSON file containing the note (called the relevance score and it a note from 0 to 1)
# of all the jobs that were scraped. Its structure is: {"ref of the offer 1": 0.002,
# "ref of the offer 2": 0.765 ...}.
scored_offers:
  type: job_finder.datasets.OptionalJSONDataset
  filepath: "abfs://relevance-scores/scored_jobs.json"
  credentials: azure_credentials
  default_data: {}

# Preprocessed jobs data ready for embedding (temporary local storage)
jobs_preprocessed:
  type: pandas.ParquetDataset
  filepath: data/02_intermediate/jobs_preprocessed.parquet

# ChromaDB vector database for job embeddings and semantic search
# Configuration flexible via variables d'environnement:
# - Mode local: CHROMA_DB_PATH=/path/to/local/db
# - Mode distant: CHROMA_HOST=ip-or-domain + CHROMA_PORT=8000
jobs_vector_db:
  type: job_finder.datasets.ChromaDataset
  collection_name: "jobs"
  # Configuration ChromaDB flexible
  chroma_host: ${oc.env:CHROMA_HOST,null}
  chroma_port: ${oc.env:CHROMA_PORT,8000}
  chroma_ssl: ${oc.env:CHROMA_SSL,false}
  persist_directory: ${oc.env:CHROMA_DB_PATH,./data/chroma}
  embedding_model: "intfloat/multilingual-e5-small"
